{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "from prompter.utilities import flatten, get_chunks, pad_sequences, dump_object, load_object, dump_json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from transformers import DistilBertTokenizer, DistilBertForTokenClassification, AdamW, BertTokenizer, BertForTokenClassification\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from kaggle_google_qa_labeling.LengthSortSampler import LengthSortSampler\n",
    "from kaggle_google_qa_labeling.dataset.cross_dataset_utilities import pad_sequences\n",
    "\n",
    "from ipdb import set_trace\n",
    "\n",
    "\n",
    "class TokenClassificationDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        if self.Y is not None:\n",
    "            return self.X[ind], self.Y[ind]\n",
    "        else:\n",
    "            return (self.X[ind], )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_collate_fn(max_len, pad_id):\n",
    "        def collate_fn(data):\n",
    "            d = list(zip(*data))\n",
    "            X = d[0]\n",
    "            Y = d[1] if len(d) == 2 else None\n",
    "\n",
    "            seq_len = min(max_len, max([len(x) for x in X]))\n",
    "\n",
    "            X = torch.LongTensor(pad_sequences(X, seq_len, 'post', pad_id))\n",
    "            \n",
    "            if Y is not None:\n",
    "                Y = torch.LongTensor(pad_sequences(Y, seq_len, 'post', pad_id))\n",
    "                res = (X, Y)\n",
    "            else:\n",
    "                res = (X,)\n",
    "\n",
    "            return res\n",
    "\n",
    "        return collate_fn\n",
    "\n",
    "    def get_data_loader(self, bs, max_len, pad_id, drop_last, use_length_sampler=True):\n",
    "\n",
    "        if use_length_sampler:\n",
    "            sampler_ = LengthSortSampler(self.X, bs=bs)\n",
    "        else:\n",
    "            sampler_ = None\n",
    "\n",
    "        dl = DataLoader(self, batch_size=bs, collate_fn=self.get_collate_fn(max_len, pad_id),\n",
    "                        sampler=sampler_, drop_last=drop_last)\n",
    "        return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = '../data/codereview.stackexchange.com/0.jsonl'\n",
    "BERT_NAME = 'bert-base-cased'\n",
    "OUT_DIR = Path(f\"../data/ner/code/{BERT_NAME.replace('-', '_')}\")\n",
    "X_CACHE_FILE = '../data/codereview.stackexchange.com/X.pkl'\n",
    "Y_CACHE_FILE = '../data/codereview.stackexchange.com/Y.pkl'\n",
    "TOKENIZER_CLS = BertTokenizer#DistilBertTokenizer\n",
    "MODEL_CLS = BertForTokenClassification#DistilBertForTokenClassification\n",
    "CODE_TOKEN = '[CODE]'\n",
    "additional_special_tokens = ['\\n', CODE_TOKEN]\n",
    "NULL_LABEL = 'null'\n",
    "MAX_LEN = 512\n",
    "MIN_LEN = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0117 13:55:30.214243 140260791818048 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/a.karnachev/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "I0117 13:55:30.244993 140260791818048 tokenization_utils.py:552] Adding \n",
      " to the vocabulary\n",
      "I0117 13:55:30.246401 140260791818048 tokenization_utils.py:552] Adding [CODE] to the vocabulary\n",
      "I0117 13:55:30.247126 140260791818048 tokenization_utils.py:629] Assigning ['\\n', '[CODE]'] to the additional_special_tokens key of the tokenizer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = TOKENIZER_CLS.from_pretrained(BERT_NAME)\n",
    "tokenizer.add_special_tokens({'additional_special_tokens': additional_special_tokens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "labels = []\n",
    "\n",
    "with open(FILE_PATH) as f:\n",
    "    for line in f:\n",
    "        d = json.loads(line)\n",
    "        texts.append(d['text'])\n",
    "        labels.append(d.get('labels', []))\n",
    "        \n",
    "id2label = sorted(set(flatten([[x[2] for x in labels_] for labels_ in labels])))\n",
    "id2label.insert(0, NULL_LABEL)\n",
    "all_texts = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    X = load_object(X_CACHE_FILE)\n",
    "    Y = load_object(Y_CACHE_FILE)\n",
    "except:\n",
    "    X = []\n",
    "    Y = []\n",
    "    pb = tqdm_notebook(zip(texts, labels), total=len(texts))\n",
    "    for text, labels_ in pb:\n",
    "        all_labels = []\n",
    "\n",
    "        for label in labels_:\n",
    "            if len(all_labels) == 0 and label[0] > 0:\n",
    "                all_labels.extend([[0, label[0], NULL_LABEL], label])\n",
    "            elif len(all_labels) == 0 and label[0] == 0:\n",
    "                all_labels.append(label)\n",
    "            elif all_labels[-1][1] == label[0]:\n",
    "                all_labels.append(label)\n",
    "            elif all_labels[-1][1] < label[0]:\n",
    "                all_labels.extend([[all_labels[-1][1], label[0], NULL_LABEL], label])\n",
    "            else:\n",
    "                raise ValueError('Unhandled case')\n",
    "\n",
    "        if len(labels_) and labels_[-1][1] != len(text):\n",
    "            all_labels.append([labels_[-1][1], len(text), NULL_LABEL])\n",
    "\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "\n",
    "        for label in all_labels:\n",
    "            text_chunk = text[label[0]:label[1]]\n",
    "            x_ = tokenizer.encode(text_chunk, add_special_tokens=False)\n",
    "            y_ = [id2label.index(label[2])] * len(x_)\n",
    "\n",
    "            x.extend(x_)\n",
    "            y.extend(y_)\n",
    "\n",
    "        for x_, y_ in zip(get_chunks(x, MAX_LEN - 2), get_chunks(y, MAX_LEN - 2)):\n",
    "            x_ = tokenizer.build_inputs_with_special_tokens(x_)\n",
    "            y_.insert(0, id2label.index(NULL_LABEL))\n",
    "            y_.append(id2label.index(NULL_LABEL))\n",
    "            assert len(x_) == len(y_)\n",
    "\n",
    "            if MAX_LEN >= len(x_) >= MIN_LEN:\n",
    "                X.append(x_)\n",
    "                Y.append(y_)\n",
    "\n",
    "    dump_object(X, X_CACHE_FILE)\n",
    "    dump_object(Y, Y_CACHE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, test_size=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0116 18:52:18.100585 140260791818048 configuration_utils.py:185] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/a.karnachev/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "I0116 18:52:18.101765 140260791818048 configuration_utils.py:199] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "I0116 18:52:18.591528 140260791818048 modeling_utils.py:406] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/a.karnachev/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
      "I0116 18:52:24.290380 140260791818048 modeling_utils.py:480] Weights of BertForTokenClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I0116 18:52:24.291194 140260791818048 modeling_utils.py:483] Weights from pretrained model not used in BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda'\n",
    "LR = 2.5e-5\n",
    "BS = 8\n",
    "N_EPOCHS = 1\n",
    "EVAL_EACH = 2000\n",
    "\n",
    "ds_train = TokenClassificationDataset(X_train, Y_train)\n",
    "dl_train = ds_train.get_data_loader(BS, MAX_LEN, tokenizer.pad_token_id, drop_last=False, use_length_sampler=True)\n",
    "ds_valid = TokenClassificationDataset(X_valid, Y_valid)\n",
    "dl_valid = ds_valid.get_data_loader(BS, MAX_LEN, tokenizer.pad_token_id, drop_last=False, use_length_sampler=True)\n",
    "\n",
    "model = MODEL_CLS.from_pretrained(BERT_NAME, num_labels=2).to(DEVICE)\n",
    "model.resize_token_embeddings(len(additional_special_tokens) + model.config.vocab_size)\n",
    "optimizer = AdamW(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56938fe74a7e474d86bc3a7815a32e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=48195), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04420299648771983\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03590635688558015\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.033086047384037025\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.036807890264530276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029497885725769495\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02985235114036917\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027491709922784963\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02793760213078471\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.036582024700603934\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026125104571878208\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025008777470397998\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024771829709598302\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02446234573752673\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024639467752386894\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023726099196339764\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022806220411981003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028000366281590208\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021351472664975085\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023555013762551938\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021270747564921977\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022244172803813668\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020891827352462342\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02023444999708757\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02141906311688885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss = np.inf\n",
    "valid_loss = np.inf\n",
    "\n",
    "pb_train = tqdm_notebook(range(N_EPOCHS))\n",
    "global_step = 0\n",
    "\n",
    "for i_epoch in pb_train:\n",
    "    \n",
    "    pb_epoch = tqdm_notebook(dl_train, total=len(dl_train), leave=False)\n",
    "\n",
    "    for X, Y in pb_epoch:\n",
    "        global_step += 1\n",
    "        X, Y = X.to(DEVICE), Y.to(DEVICE)\n",
    "        model.train()\n",
    "        \n",
    "        loss, *_ = model(X, labels=Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss = loss.item()\n",
    "\n",
    "        if global_step % EVAL_EACH == 0:\n",
    "            with torch.no_grad():\n",
    "                pb_valid = tqdm_notebook(dl_valid, total=len(dl_valid), leave=False)\n",
    "                valid_loss = 0\n",
    "                for X, Y in pb_valid:\n",
    "                    X, Y = X.to(DEVICE), Y.to(DEVICE)\n",
    "                    model.eval()\n",
    "\n",
    "                    loss, *_ = model(X, labels=Y)\n",
    "                    valid_loss += loss.item() / len(dl_valid)\n",
    "                    \n",
    "                print(valid_loss)\n",
    "                \n",
    "        postfix = {\n",
    "            'Loss/Train': train_loss,\n",
    "            'Loss/Valid': valid_loss\n",
    "        }\n",
    "        \n",
    "        pb_train.set_postfix(**postfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a.karnachev/anaconda3/envs/lab_env37/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertForTokenClassification. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/a.karnachev/anaconda3/envs/lab_env37/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/a.karnachev/anaconda3/envs/lab_env37/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/a.karnachev/anaconda3/envs/lab_env37/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/a.karnachev/anaconda3/envs/lab_env37/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LayerNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/a.karnachev/anaconda3/envs/lab_env37/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/a.karnachev/anaconda3/envs/lab_env37/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/a.karnachev/anaconda3/envs/lab_env37/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/a.karnachev/anaconda3/envs/lab_env37/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertLayer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/a.karnachev/anaconda3/envs/lab_env37/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/a.karnachev/anaconda3/envs/lab_env37/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertSelfAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/a.karnachev/anaconda3/envs/lab_env37/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/a.karnachev/anaconda3/envs/lab_env37/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertSelfOutput. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/a.karnachev/anaconda3/envs/lab_env37/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertIntermediate. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/a.karnachev/anaconda3/envs/lab_env37/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertOutput. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/a.karnachev/anaconda3/envs/lab_env37/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertPooler. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/a.karnachev/anaconda3/envs/lab_env37/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Tanh. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../data/ner/code/bert_base_cased/vocab.txt',\n",
       " '../data/ner/code/bert_base_cased/special_tokens_map.json',\n",
       " '../data/ner/code/bert_base_cased/added_tokens.json')"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG = {\n",
    "    'bert_name': BERT_NAME,\n",
    "    'tokenizer_cls': TOKENIZER_CLS.__name__,\n",
    "    'model_cls': MODEL_CLS.__name__,\n",
    "    'token': CODE_TOKEN,\n",
    "    'max_len': MAX_LEN,\n",
    "    'min_len': MIN_LEN\n",
    "}\n",
    "\n",
    "OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "torch.save(model, OUT_DIR / 'model.pth')\n",
    "dump_json(CONFIG, OUT_DIR / 'description.json')\n",
    "tokenizer.save_pretrained(OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, './model_bert_base_cased.pth')\n",
    "model = torch.load(OUT_DIR / 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0118 16:28:45.702174 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1000 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:45.737090 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2325 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:45.805295 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (7181 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:45.819558 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1407 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:45.827217 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:45.835632 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (856 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:45.844840 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (835 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:45.868813 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (682 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:45.883169 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (930 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:45.930832 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (5769 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:45.938146 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (769 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:45.946147 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:45.983489 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2061 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:45.993885 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (661 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.017900 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2444 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.037468 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.049540 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (700 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.063340 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.106282 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.151648 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2248 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.168374 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (889 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.196624 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (3318 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.206210 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.213581 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (806 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.256457 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (802 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.268864 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.302659 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (3496 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.319438 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1432 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.334187 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1586 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.358182 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.369728 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.375744 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.397877 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2490 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0118 16:28:46.405602 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (705 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.428546 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.438917 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.445019 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.452399 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.461834 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (927 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.486849 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.502541 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (759 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.526125 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (707 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.532407 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.540699 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (898 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.555679 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (714 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.578198 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2390 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.613163 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (649 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.621587 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.636190 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (927 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.663522 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (733 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.672550 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (904 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.678827 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.700827 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1872 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.719589 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.735586 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2161 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.755762 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2411 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.761895 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.773085 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (792 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.793433 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1376 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.799950 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.806621 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.830022 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2353 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.850555 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (773 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.862093 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.919759 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2921 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.930218 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (892 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.940747 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0118 16:28:46.962106 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:46.980705 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (907 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.006146 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1345 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.011683 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.024302 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1350 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.045345 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.056408 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.067673 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.081491 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (936 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.103538 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1095 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.132127 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (3150 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.164824 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (3008 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.192632 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (792 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.203904 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (855 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.211189 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (821 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.228790 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1323 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.259144 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2113 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.267910 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (902 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.281652 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1390 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.301132 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (887 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.314691 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.324421 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (945 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.334622 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (872 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.347489 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (709 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.356654 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (732 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.396991 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2364 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.430212 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1429 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.441807 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (731 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.472059 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (3302 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.477587 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.484425 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.497948 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.503586 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0118 16:28:47.516906 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (960 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.522979 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.537938 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.549564 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.563022 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1678 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.602960 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (4098 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.608765 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.619798 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.638026 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1853 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.649847 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.659817 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.680240 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1412 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.699280 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (747 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.705826 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (759 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.721779 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1448 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.728003 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.735544 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.742319 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (676 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.752850 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (869 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.772109 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1608 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.790374 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.811510 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1761 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.821025 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.849195 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1019 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.862987 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.885438 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.922134 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2335 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.934812 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.950545 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.973808 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1773 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:47.984630 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.002418 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (698 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.013075 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0118 16:28:48.024177 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (993 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.031269 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.051512 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (761 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.060549 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (888 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.074955 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.085123 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.105764 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (840 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.123173 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (914 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.134332 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (925 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.148132 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (954 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.162323 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1001 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.175722 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.201575 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (3571 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.207957 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.217219 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.235591 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (660 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.256751 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1550 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.263447 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.288159 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (3531 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.297116 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (942 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.326561 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1832 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.336106 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (779 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.364371 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2726 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.371555 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (655 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.387399 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1558 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.399615 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1310 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.417780 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1502 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.446713 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2047 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.452926 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.460605 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (787 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.475361 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.485973 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.499444 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0118 16:28:48.509440 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (944 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.533666 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1537 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.548558 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1487 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.557250 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (687 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.568974 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.581144 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1570 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.606737 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2423 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.623350 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1632 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.638342 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1605 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.645520 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (806 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.658550 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (967 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.667597 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.679097 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.686279 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (744 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.721014 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (3224 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.735722 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1534 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.744117 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (834 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.779052 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2740 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.785674 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (731 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.797176 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.811893 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.833271 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1633 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.839098 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (713 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.856817 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.866968 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.873798 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (651 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.880927 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.888187 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (704 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.904280 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (689 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.962852 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (4369 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.972391 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:48.991567 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.008824 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1738 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0118 16:28:49.025918 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.031396 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.053860 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2306 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.066177 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (935 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.104748 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.114770 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.131432 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1754 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.141555 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.148852 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.164732 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1643 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.169898 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.176409 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.192862 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1331 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.200233 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (752 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.222257 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (967 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.231154 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (892 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.241157 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (967 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.264416 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1483 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.313984 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (4434 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.337024 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2560 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.351998 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.363729 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1570 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.372163 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.398953 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (3801 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.444651 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2050 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.460217 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1442 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.477966 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.492485 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1305 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.505651 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1024 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.513588 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (834 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.544638 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (3424 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.563884 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1861 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.575896 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0118 16:28:49.585990 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (769 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.593049 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (673 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.611292 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (673 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.628307 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1540 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.645056 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.674572 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1271 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.685563 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.692308 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.717407 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.727775 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.734750 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.758963 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1968 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.766648 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.788754 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2066 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.808176 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.824568 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (668 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.835926 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (734 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.841439 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.849216 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (763 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.876888 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2290 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.883589 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (785 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.906867 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1371 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.922589 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1551 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.940121 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (815 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.952737 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (652 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:49.985657 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (3294 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.006089 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.018717 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (769 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.040197 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1268 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.045104 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.065645 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (977 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.071983 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.087517 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0118 16:28:50.096844 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (617 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.108105 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (949 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.142491 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (3098 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.151402 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (817 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.161386 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (855 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.178462 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (741 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.188893 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (784 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.194212 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.201714 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.208461 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.226355 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (813 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.243665 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1666 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.318745 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (6681 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.346365 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.356297 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (652 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.378463 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.407806 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2438 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.432982 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2129 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.449635 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (685 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.465830 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.481256 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1287 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.486720 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.502756 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.511011 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (634 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.545851 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2596 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.583574 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (875 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.592371 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (755 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.599321 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.608863 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.679424 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (7944 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.689781 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.706667 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1486 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.748277 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (4682 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0118 16:28:50.760030 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (652 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.769803 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (990 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.796392 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (3144 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.805233 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (833 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.812776 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.823358 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.843342 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.849611 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.868689 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (710 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.891469 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.905603 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1602 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.915139 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.922212 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (649 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.971617 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (976 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.985254 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.992310 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:50.998945 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.012815 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1204 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.023267 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.047459 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (765 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.092173 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (4806 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.106968 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.112971 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.122031 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.137478 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1491 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.161290 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2472 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.168599 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (736 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.175546 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (834 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.197525 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1468 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.215176 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.242726 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1996 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.260638 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (783 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.277935 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0118 16:28:51.286988 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (704 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.296529 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (862 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.307572 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.330126 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (970 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.344907 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (883 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.383715 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (4239 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.438037 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (5734 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.451489 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (987 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.467991 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.475736 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.495268 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1612 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.505106 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (735 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.514014 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (817 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.520064 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (648 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.536304 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (963 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.553448 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.559959 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (650 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.574421 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1462 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.580198 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.589431 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.598942 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (894 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.623520 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1389 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.638839 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (994 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.680623 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (3852 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.688580 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.696446 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (704 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.713156 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.721248 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (795 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.738540 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2063 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.762441 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (2527 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.779252 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1475 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.789767 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.868626 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (8673 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0118 16:28:51.877121 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (786 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.885451 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (835 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.894610 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.929615 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (3041 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.940109 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1006 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.948364 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (812 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0118 16:28:51.995788 140260791818048 tokenization_utils.py:1084] Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e9b4c31c304c55818816f284376ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=28), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "texts = all_texts[:1000]\n",
    "slices = []\n",
    "X = []\n",
    "for i, text in enumerate(texts):\n",
    "    X_ = tokenizer.encode(text, add_special_tokens=False)\n",
    "    X_ = [tokenizer.build_inputs_with_special_tokens(x) for x in get_chunks(X_, MAX_LEN - 2)]\n",
    "    \n",
    "    if len(slices) == 0:\n",
    "        slices.append(slice(0, len(X_)))\n",
    "    else:\n",
    "        slices.append(slice(slices[-1].stop, slices[-1].stop + len(X_)))\n",
    "        \n",
    "    X.extend(X_)\n",
    "    \n",
    "ds = TokenClassificationDataset(X, None)\n",
    "dl = ds.get_data_loader(64, MAX_LEN, tokenizer.pad_token_id, drop_last=False, use_length_sampler=True)\n",
    "\n",
    "Y = []\n",
    "X = []\n",
    "pb = tqdm_notebook(dl, total=len(dl))\n",
    "backsort_inds = np.argsort(dl.sampler.inds)\n",
    "with torch.no_grad():\n",
    "    for X_ in pb:\n",
    "        X_ = X_[0].to(DEVICE)\n",
    "        Y_ = model(X_)[0].detach().cpu().numpy()\n",
    "        X_ = X_.detach().cpu().numpy()\n",
    "        Y.extend(Y_)\n",
    "        X.extend(X_)\n",
    "    \n",
    "Y = [Y[i] for i in backsort_inds]\n",
    "X = [X[i] for i in backsort_inds]\n",
    "\n",
    "Y_merged = []\n",
    "X_merged = []\n",
    "for slice_ in slices:\n",
    "    Y_ = np.vstack(Y[slice_])\n",
    "    X_ = np.hstack(X[slice_])\n",
    "    Y_merged.append(Y_)\n",
    "    X_merged.append(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_decoded = []\n",
    "\n",
    "for x, y in zip(X_merged, Y_merged):\n",
    "    decoded_ = []\n",
    "    slices = []\n",
    "    cur_span = None\n",
    "    diffs = np.diff(y.argmax(1))\n",
    "    y = y.argmax(1)\n",
    "    y[0] = 0\n",
    "    y[-1] = 0\n",
    "    \n",
    "    diffs = np.diff(y)\n",
    "    s = list(np.where(diffs == 1)[0] + 1)\n",
    "    e = list(np.where(diffs == -1)[0] + 1)\n",
    "    if len(s) == len(e):\n",
    "        pass\n",
    "    elif (len(s) - len(e)) == 1:\n",
    "        e.append(len(diffs))\n",
    "    else:\n",
    "        raise ValueError('Unhandled case')\n",
    "\n",
    "    slices = [slice(s_, e_) for s_, e_ in zip(s, e)]\n",
    "\n",
    "\n",
    "    for slice_ in slices:\n",
    "        decoded_.append(tokenizer.decode(x[slice_], clean_up_tokenization_spaces=False))\n",
    "        \n",
    "    all_decoded.append(decoded_)\n",
    "\n",
    "final_texts = []\n",
    "    \n",
    "for decoded, text in zip(all_decoded, texts):\n",
    "    if len(decoded) == 0:\n",
    "        final_texts.append(text)\n",
    "        continue\n",
    "        \n",
    "    spaceless_text = text.replace(' ', '')\n",
    "    space_inds = []\n",
    "    rep_mask = np.zeros(len(text))\n",
    "\n",
    "    for i, m in enumerate(re.finditer('[^ ]+', text)):\n",
    "        space_inds.extend(list(range(*m.span())))\n",
    "\n",
    "    for d in decoded:\n",
    "        d = d.replace(' ', '')\n",
    "        for m in re.finditer(re.escape(d), spaceless_text):\n",
    "            orig_slice = slice(space_inds[m.span()[0]], space_inds[m.span()[1] - 1] + 1)\n",
    "            rep_mask[orig_slice] = 1\n",
    "\n",
    "    rep_inds = np.where(rep_mask)[0]\n",
    "    \n",
    "    if sum(rep_inds) == 0:\n",
    "        final_texts.append(text)\n",
    "        continue\n",
    "    \n",
    "    slice_bounds = [0] + list(np.where(np.diff(rep_inds) != 1)[0] + 1) + [len(rep_inds)]\n",
    "    final_slices = [slice(rep_inds[slice_bounds[i]], rep_inds[slice_bounds[i+1]-1] + 1) for i in range(len(slice_bounds)-1)]\n",
    "    final_slices = sorted(final_slices, key=lambda x: x.start)\n",
    "\n",
    "    final_text = text\n",
    "    token = CODE_TOKEN\n",
    "    shift = 0\n",
    "    for i, s in enumerate(final_slices):\n",
    "        final_text = final_text[:s.start + shift] + token + final_text[s.stop + shift:]\n",
    "        shift += len(token) - (s.stop - s.start)\n",
    "\n",
    "    pat = f'( *{token} *)+'\n",
    "    pat = re.sub('\\[', '\\[', pat)\n",
    "    pat = re.sub('\\]', '\\]', pat)\n",
    "    re.sub(pat, f' {token} ', final_text).strip()\n",
    "    final_texts.append(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab_env37",
   "language": "python",
   "name": "lab_env37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
