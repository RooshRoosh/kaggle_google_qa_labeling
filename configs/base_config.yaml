dataset_path: /absolute/path/to/cross_dataset/directory
loss: bce_losses.BCESoftLossFromLogits
model: bi_encoder_model.BiEncoderModel
seed: 228
fit_settings:
  batch_size: 1
  accum_steps: 8
  max_len: 450
  max_grad_norm: 5
  warmup_steps: 50
  eval_steps:
  epochs: 5
  optimizer: adamw
  pooling: cls
  clf_hid_dim:
  dpt: 0.3
  freeze_encoder_on_plateau_patience: 20
groups_lr:
  default: 2.5e-05
backbone:
  model: transformers.RobertaModel
  pretrained: roberta-large
device: cuda
save_fold_models: true